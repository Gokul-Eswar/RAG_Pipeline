version: "3.8"

services:
  # Kafka-compatible streaming (Redpanda)
  redpanda:
    image: vectorized/redpanda:latest
    command: ["redpanda", "start", "--overprovisioned", "--smp", "1", "--memory", "1G", "--reserve-memory", "0M", "--check", "false"]
    ports:
      - "9092:9092"
      - "9644:9644"
    volumes:
      - redpanda_data:/var/lib/redpanda/data

  # Vector database (Qdrant)
  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  # Graph database (Neo4j)
  neo4j:
    image: neo4j:5
    environment:
      NEO4J_AUTH: "neo4j/test"
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data

  # Relational DB for orchestration / metadata
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  # Airflow (light scaffold) â€” replace with your preferred orchestration image/config
  airflow:
    image: apache/airflow:2.9.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    ports:
      - "8080:8080"
    command: bash -c "airflow db upgrade || true; airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true; airflow webserver"

  # Minimal FastAPI app for the API surface
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      - qdrant
      - neo4j
      - redpanda

  # Spark (optional worker for processing)
  spark:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    ports:
      - "8081:8081"

volumes:
  redpanda_data:
  qdrant_data:
  neo4j_data:
  pgdata:

# Notes:
# - This compose file provides a developer-friendly stack. Some images (Airflow, Spark)
#   may require additional configuration for production usage.
# - Replace the `api` build with your production image or extend the Dockerfile.